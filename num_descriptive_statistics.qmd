# Descriptive Statistics: Numerical Methods

Welcome to the world of numerical descriptive methods! These techniques are your go-to tools for exploring data and understanding key concepts like distribution, central tendency, and variability. Think of them as helpful signs that guide you in figuring out how your data works.

These methods can be broadly categorized into two key areas: [measures of central tendency](https://www.nios.ac.in/media/documents/SecMathcour/Eng/Chapter-25.pdf) and [measures of dispersion](https://pmc.ncbi.nlm.nih.gov/articles/PMC3198538/). Both are crucial for painting a comprehensive picture of your data. However, we won’t be diving too deeply into these measures in this section; you can read more about them through the provided links. Instead, let’s consider something important: the choice of summary measures depends on the type of variable you’re working with. Whether you're dealing with categorical variables (like nominal and ordinal data) or numeric variables (which can be discrete or continuous), different summary statistics come into play.

![Image by pikisuperstar on Freepik](images/descriptive_stat.jpg){fig-align="center" width="300"}

<br>

## Types of Variables and Summary Measures

So, what exactly should you use when analyzing your data? Let’s break it down!

### Numerical Methods for a Single Variable

When you're focusing on just one variable, numerical methods allow you to summarize and analyze your data through various statistical measures. For numeric variables, you can explore measures of central tendency like the mean, median, and mode. These give you a glimpse into the typical values of your dataset. But that's not all—measures of dispersion, such as standard deviation, variance, and range, tell you how spread out your data is.

And don’t forget about categorical variables! For nominal and ordinal data, you can utilize frequency, proportion, and percentage to get a clearer picture of your dataset.

Here’s a handy table to summarize the types of variables and their corresponding summary measures:

+-----------------------------------------+----------------------------------------------------------+
| **Type of Variable**                    | **Summary Measures**                                     |
+=========================================+==========================================================+
| **Categorical (Nominal / Ordinal)**     | Frequency, Proportion, Percentage, Cumulative proportion |
+-----------------------------------------+----------------------------------------------------------+
| **Numeric** **(Discrete / Continuous)** | Measures of Central Tendency,                            |
|                                         |                                                          |
|                                         | Measures of Dispersion                                   |
+-----------------------------------------+----------------------------------------------------------+

<br>

### Numerical Methods for Two Variable

When you’re analyzing two variables, the methods you choose will depend on the types of variables involved. If you're working with categorical variables, like nominal and ordinal, you might find yourself comparing frequencies or proportions.

But when numeric variables enter the equation, you've got a whole new set of tools at your disposal. Think correlation and comparing means—these methods help you uncover relationships and differences between the variables, bringing you closer to understanding the data dynamics at play.

Here’s a breakdown of some of the choices available to you:

+-------------------------------------+-------------------+----------------------+-------------------------------------+
| **Type of Variables**               | **Nominal**       | **Ordinal**          | **Numeric (Discrete / Continuous)** |
+=====================================+===================+======================+=====================================+
| **Nominal**                         | Cross-tabulation  |                      |                                     |
+-------------------------------------+-------------------+----------------------+-------------------------------------+
| **Ordinal**                         | Cross-tabulation, | Cross-tabulation,    |                                     |
|                                     |                   |                      |                                     |
|                                     |                   | Spearman correlation |                                     |
+-------------------------------------+-------------------+----------------------+-------------------------------------+
| **Numeric (Discrete / Continuous)** | Compare means     | Spearman correlation | Correlation                         |
+-------------------------------------+-------------------+----------------------+-------------------------------------+

<br>

## Numerical Methods for a Single Variable using R

As we mentioned earlier, there are various ways to describe variables based on their types. In this section, we’ll explore how to describe different variables using R. First, we’ll look at numerical variables (both discrete and continuous), and then we’ll dive into categorical variables (nominal and ordinal).

```{r}
#| echo: false
#| warning: false

pacman::p_load(tidyverse, NHANES)

df1 <- NHANES::NHANES

df1 <- df1 |> 
  janitor::clean_names()

df <- df1 |> 
  select(id, survey_yr, gender, age, race1, education, marital_status, hh_income, home_own, home_rooms, poverty, work, weight, height)
```

### Describing a Single Numerical (Discrete / Categorical) Variable using R

Now, let’s explore how to describe numerical variables. We can use various measures, including mean, median, range, standard deviation, interquartile range, and percentiles.

#### Mean

The mean is the average of all the data points.

```{r}

# Calculate the mean
df |> 
  summarise(mean_age = mean(age))

```

**Another Way**

```{r}
df |> 
  pull(age) |> 
  mean()
```

What does `df |> pull(age)` means. Try yourself!

Now lets find the mean height.

```{r}

df |> 
  summarise(mean_height = mean(height))

```

**Why does the mean height show NA?**

When you try calculating the mean of the height variable, you might notice that it returns NA. This happens because some individual observations for height have missing values (NA).

To solve this, we need to tell R to ignore those missing values when performing the calculation. For this, we use an additional argument in the `mean()` function: `na.rm = TRUE`. This argument stands for “remove NAs,” and when set to `TRUE`, it ensures the missing values are ignored, allowing R to calculate the mean based on the available data.

```{r}
# Calculate the mean while having NA values

df |> 
  summarise(mean_height = mean(height), na.rm = TRUE)


```

By adding this small argument, you’ll get the correct mean without being tripped up by missing data!

<br>

#### Median

The median is the middle value when the data is ordered.

```{r}

# Calculate the median
df |> 
  summarise(median_age = median(age))


df |> 
  summarise(median_height = median(height, na.rm = TRUE))


```

Try finding median using `pull` function from the `dplyr` package.

<br>

#### Range

The range is the difference between the maximum and minimum values.

```{r}

# Calculate the range

df |> 
  pull(age) |> 
  range()

df |> 
  pull(height) |> 
  range(na.rm = TRUE)


```

If you want to find the maximum and minimum values separately, you can do this:

```{r}

# Calculate the Maximum

df |> 
  pull(age) |> 
  max()


# Calculate the Minimum

df |> 
  pull(age) |> 
  min()


```

<br>

#### Standard Deviation

Standard deviation measures the amount of variation or dispersion in a variable.

```{r}
#| eval: false


# Calculate the standard deviation
df |> 
  pull(age) |> 
  sd()

df |> 
  pull(height) |> 
  sd(na.rm = T)

```

<br>

#### Percentiles

Percentiles indicate the relative standing of a value within the dataset.

```{r}

# Calculate specific percentiles (e.g., 25th and 75th percentiles)

df |> 
  pull(age) |> 
  quantile(probs = 0.25)


df |> 
  pull(age) |> 
  quantile(probs = 0.75)


df |> 
  pull(age) |> 
  quantile(probs = c(0.25, 0.75))



```

<br>

#### Inter Quartile Range

The IQR is the range between the 25th percentile (Q1) and the 75th percentile (Q3).

```{r}

# Calculate the IQR
df |> 
  pull(age) |> 
  IQR()


```

There’s another way to approach this. We can estimate the third quartile, which represents the 75th percentile, and the first quartile, which corresponds to the 25th percentile. By calculating the difference between these two values, we arrive at the interquartile range (IQR).

```{r}

# Calculate the IQR

q_1 <- df |> 
  pull(age) |> 
  quantile(probs = 0.25)


q_3 <- df |> 
  pull(age) |> 
  quantile(probs = 0.75)


q_3 - q_1

```

#### Combining Multiple Summary Measures

If you want to combine multiple measures as a single outcome, it is also possible.

```{r}
df |> 
  summarise(
    min_age = min(age),
    q1_age = quantile(age, prob = 0.25), 
    mean_age = mean(age),
    median_age = median(age), 
    q3_age = quantile(age, prob = 0.75),
    max_age = max(age)
  )
```

<br>

### Describing a Single Categorical (Nominal / Ordinal) Variable using R

Now let’s dive into categorical variables! When working with categorical data, we often summarize it using frequencies (how often each category appears), percentages (what proportion of the total each category makes up), and cumulative percentages (the running total of those percentages). Let’s explore how to do all of this in a tidy way using R.

We’ll continue working with the NHANES dataset to see this in action.

<br>

#### Frequency

Frequency tells us how many times each category appears in the data. Let’s calculate the frequency for the income variable (`hh_income`).

```{r}
# Calculate the frequency of each category in 'hh_income'

hh_income_frequency <- df |> 
  count(hh_income)

hh_income_frequency

```

<br>

#### Percent

Next, we’ll calculate the percentage for each category, which shows the relative proportion of each category within the dataset.

```{r}
# Calculate the percentage for each category in 'hh_income'

hh_income_percent <- df  |> 
  count(hh_income) |> 
  mutate(percent = (n / sum(n)) * 100)

hh_income_percent

```

<br>

#### Cumulative Percent

Cumulative percent shows the running total of percentages, which can help understand the distribution across categories as you move through them.

```{r}
# Calculate cumulative percentage for 'hh_income'

hh_income_cumulative <- df |> 
  count(hh_income) |> 
  mutate(percent = n / sum(n) * 100,
         cumulative_percent = cumsum(percent))

hh_income_cumulative

```

### Publication Ready Tables

To create publication-ready tables, you can use the `gtsummary` package in R. Here’s an example of how to generate a summary table for a single variable dataset:

```{r}

# Install and load the gtsummary package if not already installed

# install.packages("gtsummary")

pacman::p_load(gtsummary)

# Create a summary table for the dataset
summary_table <- df |> 
  select(age, gender, race1, height) |> 
  tbl_summary(
    statistic = list(all_continuous() ~ "{mean} ({sd})", 
                     all_categorical() ~ "{n} ({p}%)"),
    digits = all_continuous() ~ 2
  )

# Print the table
summary_table


```

Try `df |> tbl_summary` without selecting variables.

## Numerical Methods for Two Variables using R

In this section, we’ll dive into how to describe relationships between two variables using R. Depending on the types of variables—categorical or numeric—the methods vary. We’ll cover three main scenarios:

-   Two categorical variables

-   Two numeric variables

-   One categorical and one numeric variable

### Two Categorical Variables

When working with two categorical variables, one of the most common ways to analyze the relationship between them is by using cross-tabulation.

Cross-tabulation creates a **contingency table** that shows the frequency distribution for each combination of categories.

Let’s use the `gender` and `race1` variables in the NHANES dataset to explore this.

#### Cross-Tabulation

```{r}

# Cross-tabulation of 'gender' and 'race1'
gender_race_table <- df %>%
  count(gender, race1)

gender_race_table

```

This table shows how the categories of gender and race1 are distributed across each other. But to make this even more informative, let’s add percentages.

#### Cross-Tabulation with Percentages

```{r}
# Cross-tabulation with percentages
gender_race_percent <- df %>%
  count(gender, race1) %>%
  group_by(gender) %>%
  mutate(percent = n / sum(n) * 100)

gender_race_percent

```

This output gives us a clearer picture of the relationship between the two categorical variables by showing the percentage of each race within each gender group.

### Two Numeric Variables

When both variables are numeric, we can correlation to explore the relationship between them.

#### Correlation

Correlation measures the strength and direction of the linear relationship between two numeric variables. The most common measure is Pearson’s correlation coefficient.

Let’s calculate the correlation between `height` and `weight`.

```{r}
df %>%
  drop_na(height, weight) |> 
  summarise(correlation = cor(height, weight))
```

**Another Way**

```{r}
# Correlation between height and weight
df %>%
  summarise(correlation = cor(height, weight, use = "complete.obs"))

```

Here, `use = "complete.obs"` ensures that rows with missing values (NA) are ignored during the correlation calculation, just like `na.rm = TRUE` would do.

### One categorical and One Numeric Variables

When you have one categorical and one numeric variable, you’re often interested in comparing the distribution of the numeric variable across different categories. Group-wise summaries and box plots are common methods for this.

Let’s look at the relationship between gender (categorical) and height (numeric).

Group-Wise Summaries We can calculate summary statistics (like mean and median) for height within each gender category.

```{r}
# Group-wise summary of height by gender
df %>%
  group_by(gender) %>%
  summarise(
    mean_height = mean(height, na.rm = TRUE),
    median_height = median(height, na.rm = TRUE),
    sd_height = sd(height, na.rm = TRUE),
    iqr_height = IQR(height, na.rm = TRUE)
  )

```

### Publication Ready Tables for Two Variables

When you need to present results in a polished, publication-ready format, the gtsummary package in R is an excellent tool. It allows you to easily create clean, professional tables summarizing relationships between two variables. Below is an example of how you can use gtsummary to generate a table for a two-variable analysis, showcasing how your results can be made ready for publication.

```{r}


# Create a publication-ready table for two categorical variables
table_cat <- df %>%
  select(gender, race1) %>%
  tbl_summary(by = gender, 
              label = race1 ~ "Race/Ethnicity") 

# Display the table
table_cat

```

If you're comparing a numeric variable across categories (e.g., height by gender), use the `tbl_summary()` function with the `by` argument.

```{r}


# Create a publication-ready table for a categorical and a numeric variables

table_cat_num <- df  |> 
  select(gender, height) |> 
  drop_na() |> 
  tbl_summary(by = gender, 
              label = height ~ "Height") 

# Display the table
table_cat_num

```

If you need mean and standard deviation instead of median and IQR, then

```{r}
table_cat_num <- df  |> 
  select(gender, height) |> 
  drop_na() |> 
  tbl_summary(
    by = gender,
    statistic = list(all_continuous() ~ "{mean} ({sd})")
  ) 

# Display the table
table_cat_num
```
