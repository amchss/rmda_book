[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Research Methodologies & Data Analysis Using R",
    "section": "",
    "text": "About Book"
  },
  {
    "objectID": "descriptive_statistics.html",
    "href": "descriptive_statistics.html",
    "title": "1  Descriptive Statistics",
    "section": "",
    "text": "1.1 Goal",
    "crumbs": [
      "Statistical Methods",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Descriptive Statistics</span>"
    ]
  },
  {
    "objectID": "descriptive_statistics.html#goal",
    "href": "descriptive_statistics.html#goal",
    "title": "9  Descriptive Statistics",
    "section": "9.1 Goal",
    "text": "9.1 Goal\n\nThe goal of this session is to introduce the basic concepts of descriptive analysis, focusing on how to summarize and present data in meaningful ways. By the end of this chapter, students will:\n\nBe able to describe variables using both graphical and numerical methods"
  },
  {
    "objectID": "descriptive_statistics.html#what-is-descriptive-analysis",
    "href": "descriptive_statistics.html#what-is-descriptive-analysis",
    "title": "9  Descriptive Statistics",
    "section": "9.2 What is Descriptive Analysis",
    "text": "9.2 What is Descriptive Analysis\n\nDescriptive analysis is a statistical method used to summarize and describe the main features of a dataset. It provides a simple overview of the data, highlighting key aspects such as central tendency, variability, and distribution. This type of analysis is essential for understanding the basic characteristics of the data before applying more complex statistical methods.\nDescriptive methods can be categorized into two types:\n\n\nGraphical Descriptive Methods\nNumerical Descriptive Methods\n\n\nIn the following chapters, we will describe each of these methods in detail. Let’s deepen your understanding of graphical and numerical descriptive methods, as well as how to implement these techniques using R."
  },
  {
    "objectID": "graph_descriptive_statistics.html",
    "href": "graph_descriptive_statistics.html",
    "title": "2  Descriptive Statistics: Graphical Methods",
    "section": "",
    "text": "2.1 Graphical Methods for a Single Variable",
    "crumbs": [
      "Statistical Methods",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Descriptive Statistics: Graphical Methods</span>"
    ]
  },
  {
    "objectID": "graph_descriptive_statistics.html#graphical-methods-for-a-single-variable",
    "href": "graph_descriptive_statistics.html#graphical-methods-for-a-single-variable",
    "title": "10  Descriptive Statistics: Graphical Methods",
    "section": "10.1 Graphical Methods for a Single Variable",
    "text": "10.1 Graphical Methods for a Single Variable\n\n\n\n\n\n\n\n\nVariable Type\nGraphical Method\nDescription\n\n\n\n\nCategorical (Nominal / Ordinal)\nBar Chart\nShows frequency or proportion of categories\n\n\nDiscrete (Integer)\nHistogram\nDisplays the count of values across defined intervals\n\n\n\nDot Plot\nShows individual data points for small datasets\n\n\nContinuous (Double)\nHistogram\nShows the frequency distribution of continuous values\n\n\n\nBox Plot\nDisplays distribution, including outliers\n\n\n\nDensity Plot\nVisualizes the density function"
  },
  {
    "objectID": "graph_descriptive_statistics.html#graphical-methods-for-two-variable-visualization",
    "href": "graph_descriptive_statistics.html#graphical-methods-for-two-variable-visualization",
    "title": "10  Descriptive Statistics: Graphical Methods",
    "section": "10.2 Graphical Methods for Two Variable Visualization",
    "text": "10.2 Graphical Methods for Two Variable Visualization\n\n\n\n\n\n\n\n\n\nCategorical (Nominal / Ordinal)\nNumeric (Discrete / Continuous)\n\n\n\n\nCategorical (Nominal / Ordinal)\nStacked Bar Chart\nGrouped Bar Chart\n\n\nNumeric (Discrete / Continuous)\nGrouped Bar Chart\nScatter Plot"
  },
  {
    "objectID": "graph_descriptive_statistics.html#data-visualization-using-r-introduction-to-grammar-of-graphics",
    "href": "graph_descriptive_statistics.html#data-visualization-using-r-introduction-to-grammar-of-graphics",
    "title": "10  Descriptive Statistics: Graphical Methods",
    "section": "10.3 Data Visualization Using R: Introduction to Grammar of Graphics",
    "text": "10.3 Data Visualization Using R: Introduction to Grammar of Graphics\n\nData visualization in R can be effectively done using the ggplot2 package, which is included in the popular tidyverse collection of R packages. ggplot2 is based on the Grammar of Graphics, a structured approach that allows you to build plots layer by layer. This grammar provides a framework for describing and creating visualizations by combining different graphical elements. The idea is that any plot can be constructed by breaking it down into components.\nThe visualisation using ggplot2 package, which follows the philosophy of grammar of graphics, breaks down a plot into several components:\n\nData: The dataset you’re working with.\nAesthetics: The visual properties (e.g., axes, colors, sizes).\nGeometries: The type of plot (e.g., points, bars, lines).\nFacets: Dividing the data into subplots.\nScales: Mapping of data values to visual properties.\nCoordinates: How data is projected onto the plane (e.g., Cartesian coordinates).\n\n\nWhat Happens When You Run ggplot()?\nWhen you run ggplot() in R without specifying any further components, it provides you with a blank “canvas” (or plane) on which you can build your plot. This is like opening a blank sheet of paper to start drawing. Here’s an example:\n\n# Load Packages\n#install.packages(pacman)\n\npacman::p_load(tidyverse, here)\n\n# Load Data\n\ndf1 <- NHANES::NHANES\n\ndf1 <- df1 |> \n  janitor::clean_names()\n\ndf <- df1 |> \n  select(id, survey_yr, gender, age, race1, education, marital_status, hh_income, home_own, home_rooms, poverty, work, weight, height)\n\n\n# Running ggplot without specifying layers\nggplot()\n\n\n\n\nThis will simply give you a blank plot. You then need to add layers to specify what the plot will contain.\n\n\n\nAesthetics (aes)\n\nAesthetic mappings define how data is mapped to visual properties. They include properties such as:\n\nx and y axes: Mapped to variables in your data.\ncolor: Used to differentiate categories.\nsize: Used to represent magnitude or importance.\n\nFor example, when you add aesthetics to ggplot(), it tells R how to map data to the plot:\n\nggplot(data = df, \n       mapping = aes(x = height, y = weight))\n\n\n\n\nIn this example, height is mapped to the x-axis and weight to the y-axis\n\n\n\nLayers in ggplot2\n\nThe power of ggplot2 lies in its layering system. After creating the base plot with ggplot(), you can add multiple layers.\nYou add these layers using the + operator\nFor Example:\n\n# Adding layers to create a plot\nggplot(df, aes(x = height, y = weight)) +\n  geom_point() +\n  labs(title = \"Height vs Weight\",\n       caption = \"Source: NHANES Data\") \n\nWarning: Removed 366 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nHere’s a breakdown of each layer in the example:\n\nggplot(df, aes(x = height, y = weight)): This initializes the plot using the df dataset. Inside aes(), the x-axis is mapped to xvariable (height), and the y-axis is mapped to yvariable (weight). The aes() function defines aesthetic mappings, determining how data is represented visually.\ngeom_point(): This adds a geometric layer, specifically a scatter plot, where each point represents an observation. It visualizes the relationship between x and y\nlabs(title = \"Height vs Weight\", caption = \"Source: NHANES Data\"): This layer adds a title and a caption to the plot, making it more interpretable. The title helps to explain what the plot is displaying.\n\nEach layer builds on the previous one, progressively adding more information to the visualization.\nNote\nEvery geometric layer starts with geom_ in ggplot2."
  },
  {
    "objectID": "graph_descriptive_statistics.html#visualising-a-single-variable-using-r",
    "href": "graph_descriptive_statistics.html#visualising-a-single-variable-using-r",
    "title": "10  Descriptive Statistics: Graphical Methods",
    "section": "10.4 Visualising a Single Variable using R",
    "text": "10.4 Visualising a Single Variable using R\n\nGraphical methods are essential for summarizing and understanding the distribution of a single variable. In this section, we will explore different types of plots for visualizing one variable, based on its type (nominal, ordinal, discrete, or continuous). The key graphical methods include bar charts, boxplots, histograms, and density plots.\n\n\n10.4.1 Bar Chart\n\nA bar chart is used to represent categorical data (nominal or ordinal). Each bar represents the frequency (or count) of a category. It’s commonly used for visualizing nominal variables like gender or education level.\nExample:\n\n# Bar chart example for a nominal variable\n\nggplot(df, aes(x = gender)) +\n  geom_bar() +\n  labs(\n    title = \"Bar Chart of Gender\", \n    x = \"Gender\", \n    y = \"Count\")\n\n\n\n\n\n\n\n10.4.2 Boxplot\n\nA boxplot is used to represent the distribution of a continuous variable. It shows the median, quartiles, and potential outliers.\nExample:\n\n# Boxplot example for a continuous variable\nggplot(df, aes(y = height)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot of Height\")\n\nWarning: Removed 353 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n10.4.3 Histogram\n\nA histogram is used to visualize the distribution of a continuous variable by dividing the data into bins and counting the number of observations in each bin. It’s useful for understanding the shape, spread, and central tendency of continuous variables like age or income.\nExample:\n\n# Histogram example for a continuous variable\nggplot(df, aes(x = height)) +\n  geom_histogram() +\n  labs(title = \"Histogram of Height\", x = \"Height\", y = \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 353 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\nHere the x-axis represents height (a continuous variable), and the y-axis represents the frequency of observations in each height bin.\nWe can make the histogram more attractive.\n\nggplot(df, aes(x = height)) +\n  geom_histogram(binwidth = 2, \n                 fill = \"blue\", \n                 color = \"black\") +\n  labs(title = \"Histogram of Height\", \n       x = \"Height\", \n       y = \"Frequency\") +\n  theme_minimal()\n\nWarning: Removed 353 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n10.4.4 Density Plot\n\nA density plot is a smoothed version of a histogram, used for continuous data. It provides an estimate of the probability distribution of a continuous variable.\n\n# Density plot example for a continuous variable\nggplot(df, aes(x = height)) +\n  geom_density(\n    alpha = 0.5) +\n  labs(\n    title = \"Density Plot of Height\", \n    x = \"Height\") +\ntheme_minimal()\n\nWarning: Removed 353 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\nWe can represent the area under the curve using any color.\n\n# Density plot example for a continuous variable\nggplot(df, aes(x = height)) +\n  geom_density(\n    fill = \"green\", \n    alpha = 0.5) +\n  labs(\n    title = \"Density Plot of Height\", \n    x = \"Height\") +\ntheme_minimal()\n\nWarning: Removed 353 rows containing non-finite outside the scale range\n(`stat_density()`).\n\n\n\n\n\n\n\n\n10.4.5 Combining Multiple Geometries: Overlaying Histogram and Density Plot\n\nOne of the strengths of ggplot2 is its ability to add multiple geometric shapes (geoms) to a single plot. For example, you can overlay a density plot on top of a histogram to visualize both the frequency distribution and the smoothed probability distribution of a continuous variable in a single canvas.\nExample: Histogram and Density Plot Together\n\n# Combining histogram and density plot\n\n\nlibrary(ggplot2)\n\nggplot(df, aes(x = height)) +\n  # Histogram with density scaling\n  geom_histogram(\n    aes(y = after_stat(density)),        # Normalize the histogram to show density instead of counts\n    binwidth = 2,                # Sets the bin width for the histogram\n    fill = \"blue\",               # Fills the bars with blue color\n    color = \"black\",             # Outlines the bars with black\n    alpha = 0.6                  # Adds transparency to the bars\n  ) +\n  # Density plot\n  geom_density(\n    aes(y = after_stat(density)),        # Ensures the y-axis of density is consistent\n    color = \"red\",               # The density plot will be red\n    linewidth = 1                     # Thickness of the density line\n  ) +\n  # Labels\n  labs(\n    title = \"Histogram and Density Plot of Height\",  # Title for the plot\n    x = \"Height\",                                    # X-axis label\n    y = \"Density\"                                    # Y-axis label\n  ) +\n  theme_minimal()                                     # Apply a clean theme\n\nWarning: Removed 353 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\nWarning: Removed 353 rows containing non-finite outside the scale range\n(`stat_density()`)."
  },
  {
    "objectID": "graph_descriptive_statistics.html#visualising-two-variables-using-r",
    "href": "graph_descriptive_statistics.html#visualising-two-variables-using-r",
    "title": "10  Descriptive Statistics: Graphical Methods",
    "section": "10.5 Visualising Two Variables using R",
    "text": "10.5 Visualising Two Variables using R\n\nWhen working with two variables, visualizing the relationship between them helps reveal patterns, associations, or differences. The appropriate plot depends on the types of variables involved (categorical, continuous, or a combination). In this section, we will explore different graphical methods for visualizing two variables: stacked bar charts, grouped bar charts, scatter plots, box plots by category, and regression lines with standard error.\n\n\n10.5.1 Stacked Bar Chart\n\nA stacked bar chart is used when both variables are categorical. It displays the distribution of one variable while stacking the bars based on the categories of the second variable.\nExample:\n\n# Stacked bar chart example for two categorical variables\n\nggplot(df, aes(x = gender, fill = race1)) +\n  geom_bar(position = \"stack\") +\n  labs(title = \"Stacked Bar Chart of Gender by Race\", x = \"Gender\", y = \"Count\", fill = \"Race\")\n\n\n\n\n\n\n\n10.5.2 Grouped Bar Chart\n\nA grouped bar chart is another option for visualizing two categorical variables. Instead of stacking the bars, it places bars for each category side-by-side, allowing for a clearer comparison between categories.\nExample:\n\n# Grouped bar chart example for two categorical variables\n\n\nggplot(df, aes(x = race1, fill = gender)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Grouped Bar Chart of Gender by Race\", x = \"Gender\", y = \"Count\", fill = \"Race\")\n\n\n\n\n\n\n\n10.5.3 Scatter Plot\n\nA scatter plot is used to visualize the relationship between two continuous variables. Each point on the plot represents an observation, and patterns like clusters, trends, or outliers can be detected.\nExample:\n\n# Scatter plot example for two continuous variables\nggplot(df, aes(x = height, y = weight)) +\n  geom_point() +\n  labs(title = \"Height vs Weight\",\n       caption = \"Source: NHANES Data\")\n\nWarning: Removed 366 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n10.5.4 Box Plot by Category\n\nA box plot by category is useful when comparing the distribution of a continuous variable across different categories of a categorical variable. It shows the median, quartiles, and potential outliers within each category.\nExample:\n\n# Box plot example for a continuous variable by category\n\nggplot(df, aes(x = gender, y = height)) +\n  geom_boxplot() +\n  labs(title = \"Box Plot of Height by Gender\", x = \"Gender\", y = \"Height\")\n\nWarning: Removed 353 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n10.5.5 Combining Multiple Geometries: Scatter Plot with Regression Line\n\nA scatter plot with a regression line helps visualize the relationship between two continuous variables. Adding a regression line shows the trend, while the standard error (SE) band around the line indicates the uncertainty in the estimate of the relationship.\nWhile regression is an inferential method (used for making predictions or understanding relationships), the purpose of this example is to demonstrate how multiple geometries can be combined when visualizing two variables.\nExample:\n\n# Scatter plot with regression line and SE\n\n\nggplot(df, aes(x = height, y = weight)) +\n  geom_point(color = \"blue\", alpha = 0.6) +    # Add scatter plot points\n  geom_smooth(method = \"lm\",                   # Add a regression line\n              color = \"red\",                   # Set the color of the line\n              se = TRUE,                       # Add the SE band (uncertainty)\n              fill = \"lightgray\",              # Color of the SE band\n              size = 1) +                      # Set thickness of the line\n  labs(\n    title = \"Scatter Plot with Regression Line and SE Band\",  # Title\n    x = \"Height (cm)\",                                        # X-axis label\n    y = \"Weight (kg)\"                                         # Y-axis label\n  ) +\n  theme_minimal()                                              # Apply a clean theme\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 366 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 366 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "graph_descriptive_statistics.html#visualizing-three-variables-using-r",
    "href": "graph_descriptive_statistics.html#visualizing-three-variables-using-r",
    "title": "10  Descriptive Statistics: Graphical Methods",
    "section": "10.6 Visualizing Three Variables using R",
    "text": "10.6 Visualizing Three Variables using R\n\nWhen working with three variables, we can extend basic plots like scatter plots by adding a third variable as an aesthetic element such as color or fill. This allows us to represent more dimensions of the data in a single plot. One common approach is to use color to represent a categorical or continuous variable in a scatter plot.\nExample: Scatter Plot with Color for a Third Variable\nIn this example, we’ll create a scatter plot of two continuous variables and use color to represent a third categorical variable. This can help identify patterns or groupings based on the third variable.\n\n\nExample\n\n# Scatter plot with color representing a third variable\n\nggplot(df, \n       aes(x = height, \n           y = weight, \n           color = race1)) +\n  geom_point(size = 1, alpha = 0.5) +\n  labs(title = \"Scatter Plot of Height vs Weight by Race\", \n       x = \"Height\", y = \"Weight\", color = \"Race\")\n\nWarning: Removed 366 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nAnother Way\n\n# Scatter plot with color representing a third variable\n\nggplot(df, \n       aes(x = height, \n           y = weight)) +\n  geom_point(size = 1) +\n    facet_wrap(~race1)+\n  labs(title = \"Scatter Plot of Height vs Weight by Race\", \n       x = \"Height\", y = \"Weight\", color = \"Race\")\n\nWarning: Removed 366 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "graph_descriptive_statistics.html#visualizing-four-variables-using-r",
    "href": "graph_descriptive_statistics.html#visualizing-four-variables-using-r",
    "title": "10  Descriptive Statistics: Graphical Methods",
    "section": "10.7 Visualizing Four Variables using R",
    "text": "10.7 Visualizing Four Variables using R\n\nTo visualize four variables, we can use a combination of color (or fill) for the third variable and facet wrapping for the fourth variable. Facet wrapping creates a series of smaller plots based on the levels of a categorical variable, allowing us to compare the relationships across different subgroups.\nExample: Scatter Plot with Color and Facet Wrap\nIn this example, we’ll use a scatter plot with color representing a third variable, and facet wrapping to display different plots for each level of the fourth variable.\n\n# Scatter plot with color and facet wrap for a fourth variable\nggplot(df, \n       aes(x = height, \n           y = weight,\n           color = gender)) +\n  geom_point(size = 1) +\n    facet_wrap(~race1)+\n  labs(title = \"Scatter Plot of Height vs Weight by Race and gender\", \n       x = \"Height\", y = \"Weight\", color = \"Gender\")\n\nWarning: Removed 366 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "num_descriptive_statistics.html",
    "href": "num_descriptive_statistics.html",
    "title": "3  Descriptive Statistics: Numerical Methods",
    "section": "",
    "text": "3.1 Types of Variables and Summary Measures",
    "crumbs": [
      "Statistical Methods",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics: Numerical Methods</span>"
    ]
  },
  {
    "objectID": "num_descriptive_statistics.html#types-of-variables-and-summary-measures",
    "href": "num_descriptive_statistics.html#types-of-variables-and-summary-measures",
    "title": "11  Descriptive Statistics: Numerical Methods",
    "section": "11.1 Types of Variables and Summary Measures",
    "text": "11.1 Types of Variables and Summary Measures\n\nSo, what exactly should you use when analyzing your data? Let’s break it down!\n\n\n11.1.1 Numerical Methods for a Single Variable\n\nWhen you’re focusing on just one variable, numerical methods allow you to summarize and analyze your data through various statistical measures. For numeric variables, you can explore measures of central tendency like the mean, median, and mode. These give you a glimpse into the typical values of your dataset. But that’s not all—measures of dispersion, such as standard deviation, variance, and range, tell you how spread out your data is.\nAnd don’t forget about categorical variables! For nominal and ordinal data, you can utilize frequency, proportion, and percentage to get a clearer picture of your dataset.\nHere’s a handy table to summarize the types of variables and their corresponding summary measures:\n\n\n\n\n\n\n\n\nType of Variable\nSummary Measures\n\n\n\n\nCategorical (Nominal / Ordinal)\nFrequency, Proportion, Percentage, Cumulative proportion\n\n\nNumeric (Discrete / Continuous)\nMeasures of Central Tendency,\nMeasures of Dispersion\n\n\n\n\n\n\n11.1.2 Numerical Methods for Two Variable\n\nWhen you’re analyzing two variables, the methods you choose will depend on the types of variables involved. If you’re working with categorical variables, like nominal and ordinal, you might find yourself comparing frequencies or proportions.\nBut when numeric variables enter the equation, you’ve got a whole new set of tools at your disposal. Think correlation and comparing means—these methods help you uncover relationships and differences between the variables, bringing you closer to understanding the data dynamics at play.\nHere’s a breakdown of some of the choices available to you:\n\n\n\n\n\n\n\n\n\n\nType of Variables\nNominal\nOrdinal\nNumeric (Discrete / Continuous)\n\n\n\n\nNominal\nCross-tabulation\n\n\n\n\nOrdinal\nCross-tabulation,\nCross-tabulation,\nSpearman correlation\n\n\n\nNumeric (Discrete / Continuous)\nCompare means\nSpearman correlation\nCorrelation"
  },
  {
    "objectID": "num_descriptive_statistics.html#numerical-methods-for-a-single-variable-using-r",
    "href": "num_descriptive_statistics.html#numerical-methods-for-a-single-variable-using-r",
    "title": "11  Descriptive Statistics: Numerical Methods",
    "section": "11.2 Numerical Methods for a Single Variable using R",
    "text": "11.2 Numerical Methods for a Single Variable using R\n\nAs we mentioned earlier, there are various ways to describe variables based on their types. In this section, we’ll explore how to describe different variables using R. First, we’ll look at numerical variables (both discrete and continuous), and then we’ll dive into categorical variables (nominal and ordinal).\n\n\n\n\n\n11.2.1 Describing a Single Numerical (Discrete / Categorical) Variable using R\n\nNow, let’s explore how to describe numerical variables. We can use various measures, including mean, median, range, standard deviation, interquartile range, and percentiles.\n\n\n11.2.1.1 Mean\n\nThe mean is the average of all the data points.\n\n# Calculate the mean\ndf |> \n  summarise(mean_age = mean(age))\n\n# A tibble: 1 × 1\n  mean_age\n     <dbl>\n1     36.7\n\n\nAnother Way\n\ndf |> \n  pull(age) |> \n  mean()\n\n[1] 36.7421\n\n\nWhat does df |> pull(age) means. Try yourself!\nNow lets find the mean height.\n\ndf |> \n  summarise(mean_height = mean(height))\n\n# A tibble: 1 × 1\n  mean_height\n        <dbl>\n1          NA\n\n\nWhy does the mean height show NA?\nWhen you try calculating the mean of the height variable, you might notice that it returns NA. This happens because some individual observations for height have missing values (NA).\nTo solve this, we need to tell R to ignore those missing values when performing the calculation. For this, we use an additional argument in the mean() function: na.rm = TRUE. This argument stands for “remove NAs,” and when set to TRUE, it ensures the missing values are ignored, allowing R to calculate the mean based on the available data.\n\n# Calculate the mean while having NA values\n\ndf |> \n  summarise(mean_height = mean(height), na.rm = TRUE)\n\n# A tibble: 1 × 2\n  mean_height na.rm\n        <dbl> <lgl>\n1          NA TRUE \n\n\nBy adding this small argument, you’ll get the correct mean without being tripped up by missing data!\n\n\n\n\n11.2.1.2 Median\n\nThe median is the middle value when the data is ordered.\n\n# Calculate the median\ndf |> \n  summarise(median_age = median(age))\n\n# A tibble: 1 × 1\n  median_age\n       <dbl>\n1         36\n\ndf |> \n  summarise(median_height = median(height, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  median_height\n          <dbl>\n1           166\n\n\nTry finding median using pull function from the dplyr package.\n\n\n\n\n11.2.1.3 Range\n\nThe range is the difference between the maximum and minimum values.\n\n# Calculate the range\n\ndf |> \n  pull(age) |> \n  range()\n\n[1]  0 80\n\ndf |> \n  pull(height) |> \n  range(na.rm = TRUE)\n\n[1]  83.6 200.4\n\n\nIf you want to find the maximum and minimum values separately, you can do this:\n\n# Calculate the Maximum\n\ndf |> \n  pull(age) |> \n  max()\n\n[1] 80\n\n# Calculate the Minimum\n\ndf |> \n  pull(age) |> \n  min()\n\n[1] 0\n\n\n\n\n\n\n11.2.1.4 Standard Deviation\n\nStandard deviation measures the amount of variation or dispersion in a variable.\n\n# Calculate the standard deviation\ndf |> \n  pull(age) |> \n  sd()\n\ndf |> \n  pull(height) |> \n  sd(na.rm = T)\n\n\n\n\n\n11.2.1.5 Percentiles\n\nPercentiles indicate the relative standing of a value within the dataset.\n\n# Calculate specific percentiles (e.g., 25th and 75th percentiles)\n\ndf |> \n  pull(age) |> \n  quantile(probs = 0.25)\n\n25% \n 17 \n\ndf |> \n  pull(age) |> \n  quantile(probs = 0.75)\n\n75% \n 54 \n\ndf |> \n  pull(age) |> \n  quantile(probs = c(0.25, 0.75))\n\n25% 75% \n 17  54 \n\n\n\n\n\n\n11.2.1.6 Inter Quartile Range\n\nThe IQR is the range between the 25th percentile (Q1) and the 75th percentile (Q3).\n\n# Calculate the IQR\ndf |> \n  pull(age) |> \n  IQR()\n\n[1] 37\n\n\nThere’s another way to approach this. We can estimate the third quartile, which represents the 75th percentile, and the first quartile, which corresponds to the 25th percentile. By calculating the difference between these two values, we arrive at the interquartile range (IQR).\n\n# Calculate the IQR\n\nq_1 <- df |> \n  pull(age) |> \n  quantile(probs = 0.25)\n\n\nq_3 <- df |> \n  pull(age) |> \n  quantile(probs = 0.75)\n\n\nq_3 - q_1\n\n75% \n 37 \n\n\n\n\n\n11.2.1.7 Combining Multiple Summary Measures\n\nIf you want to combine multiple measures as a single outcome, it is also possible.\n\ndf |> \n  summarise(\n    min_age = min(age),\n    q1_age = quantile(age, prob = 0.25), \n    mean_age = mean(age),\n    median_age = median(age), \n    q3_age = quantile(age, prob = 0.75),\n    max_age = max(age)\n  )\n\n# A tibble: 1 × 6\n  min_age q1_age mean_age median_age q3_age max_age\n    <int>  <dbl>    <dbl>      <dbl>  <dbl>   <int>\n1       0     17     36.7         36     54      80\n\n\n\n\n\n\n\n11.2.2 Describing a Single Categorical (Nominal / Ordinal) Variable using R\n\nNow let’s dive into categorical variables! When working with categorical data, we often summarize it using frequencies (how often each category appears), percentages (what proportion of the total each category makes up), and cumulative percentages (the running total of those percentages). Let’s explore how to do all of this in a tidy way using R.\nWe’ll continue working with the NHANES dataset to see this in action.\n\n\n\n11.2.2.1 Frequency\n\nFrequency tells us how many times each category appears in the data. Let’s calculate the frequency for the income variable (hh_income).\n\n# Calculate the frequency of each category in 'hh_income'\n\nhh_income_frequency <- df |> \n  count(hh_income)\n\nhh_income_frequency\n\n# A tibble: 13 × 2\n   hh_income         n\n   <fct>         <int>\n 1 \" 0-4999\"       192\n 2 \" 5000-9999\"    254\n 3 \"10000-14999\"   543\n 4 \"15000-19999\"   527\n 5 \"20000-24999\"   617\n 6 \"25000-34999\"   958\n 7 \"35000-44999\"   863\n 8 \"45000-54999\"   784\n 9 \"55000-64999\"   621\n10 \"65000-74999\"   526\n11 \"75000-99999\"  1084\n12 \"more 99999\"   2220\n13  <NA>           811\n\n\n\n\n\n\n11.2.2.2 Percent\n\nNext, we’ll calculate the percentage for each category, which shows the relative proportion of each category within the dataset.\n\n# Calculate the percentage for each category in 'hh_income'\n\nhh_income_percent <- df  |> \n  count(hh_income) |> \n  mutate(percent = (n / sum(n)) * 100)\n\nhh_income_percent\n\n# A tibble: 13 × 3\n   hh_income         n percent\n   <fct>         <int>   <dbl>\n 1 \" 0-4999\"       192    1.92\n 2 \" 5000-9999\"    254    2.54\n 3 \"10000-14999\"   543    5.43\n 4 \"15000-19999\"   527    5.27\n 5 \"20000-24999\"   617    6.17\n 6 \"25000-34999\"   958    9.58\n 7 \"35000-44999\"   863    8.63\n 8 \"45000-54999\"   784    7.84\n 9 \"55000-64999\"   621    6.21\n10 \"65000-74999\"   526    5.26\n11 \"75000-99999\"  1084   10.8 \n12 \"more 99999\"   2220   22.2 \n13  <NA>           811    8.11\n\n\n\n\n\n\n11.2.2.3 Cumulative Percent\n\nCumulative percent shows the running total of percentages, which can help understand the distribution across categories as you move through them.\n\n# Calculate cumulative percentage for 'hh_income'\n\nhh_income_cumulative <- df |> \n  count(hh_income) |> \n  mutate(percent = n / sum(n) * 100,\n         cumulative_percent = cumsum(percent))\n\nhh_income_cumulative\n\n# A tibble: 13 × 4\n   hh_income         n percent cumulative_percent\n   <fct>         <int>   <dbl>              <dbl>\n 1 \" 0-4999\"       192    1.92               1.92\n 2 \" 5000-9999\"    254    2.54               4.46\n 3 \"10000-14999\"   543    5.43               9.89\n 4 \"15000-19999\"   527    5.27              15.2 \n 5 \"20000-24999\"   617    6.17              21.3 \n 6 \"25000-34999\"   958    9.58              30.9 \n 7 \"35000-44999\"   863    8.63              39.5 \n 8 \"45000-54999\"   784    7.84              47.4 \n 9 \"55000-64999\"   621    6.21              53.6 \n10 \"65000-74999\"   526    5.26              58.8 \n11 \"75000-99999\"  1084   10.8               69.7 \n12 \"more 99999\"   2220   22.2               91.9 \n13  <NA>           811    8.11             100   \n\n\n\n\n\n\n11.2.3 Publication Ready Tables\n\nTo create publication-ready tables, you can use the gtsummary package in R. Here’s an example of how to generate a summary table for a single variable dataset:\n\n# Install and load the gtsummary package if not already installed\n\n# install.packages(\"gtsummary\")\n\npacman::p_load(gtsummary)\n\n# Create a summary table for the dataset\nsummary_table <- df |> \n  select(age, gender, race1, height) |> \n  tbl_summary(\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\", \n                     all_categorical() ~ \"{n} ({p}%)\"),\n    digits = all_continuous() ~ 2\n  )\n\n# Print the table\nsummary_table\n\n\n\n\n\n  \n    \n      Characteristic\n\n      N = 10,000\n1\n    \n  \n  \n    age\n36.74 (22.40)\n    gender\n\n        female\n5,020 (50%)\n        male\n4,980 (50%)\n    race1\n\n        Black\n1,197 (12%)\n        Hispanic\n610 (6.1%)\n        Mexican\n1,015 (10%)\n        White\n6,372 (64%)\n        Other\n806 (8.1%)\n    height\n161.88 (20.19)\n        Unknown\n353\n  \n  \n  \n    \n      1 Mean (SD); n (%)\n\n    \n  \n\n\n\n\nTry df |> tbl_summary without selecting variables."
  },
  {
    "objectID": "num_descriptive_statistics.html#numerical-methods-for-two-variables-using-r",
    "href": "num_descriptive_statistics.html#numerical-methods-for-two-variables-using-r",
    "title": "11  Descriptive Statistics: Numerical Methods",
    "section": "11.3 Numerical Methods for Two Variables using R",
    "text": "11.3 Numerical Methods for Two Variables using R\n\nIn this section, we’ll dive into how to describe relationships between two variables using R. Depending on the types of variables—categorical or numeric—the methods vary. We’ll cover three main scenarios:\n\nTwo categorical variables\nTwo numeric variables\nOne categorical and one numeric variable\n\n\n\n11.3.1 Two Categorical Variables\n\nWhen working with two categorical variables, one of the most common ways to analyze the relationship between them is by using cross-tabulation.\nCross-tabulation creates a contingency table that shows the frequency distribution for each combination of categories.\nLet’s use the gender and race1 variables in the NHANES dataset to explore this.\n\n\n11.3.1.1 Cross-Tabulation\n\n# Cross-tabulation of 'gender' and 'race1'\ngender_race_table <- df %>%\n  count(gender, race1)\n\ngender_race_table\n\n# A tibble: 10 × 3\n   gender race1        n\n   <fct>  <fct>    <int>\n 1 female Black      614\n 2 female Hispanic   320\n 3 female Mexican    452\n 4 female White     3221\n 5 female Other      413\n 6 male   Black      583\n 7 male   Hispanic   290\n 8 male   Mexican    563\n 9 male   White     3151\n10 male   Other      393\n\n\n\nThis table shows how the categories of gender and race1 are distributed across each other. But to make this even more informative, let’s add percentages.\n\n\n\n11.3.1.2 Cross-Tabulation with Percentages\n\n# Cross-tabulation with percentages\ngender_race_percent <- df %>%\n  count(gender, race1) %>%\n  group_by(gender) %>%\n  mutate(percent = n / sum(n) * 100)\n\ngender_race_percent\n\n# A tibble: 10 × 4\n# Groups:   gender [2]\n   gender race1        n percent\n   <fct>  <fct>    <int>   <dbl>\n 1 female Black      614   12.2 \n 2 female Hispanic   320    6.37\n 3 female Mexican    452    9.00\n 4 female White     3221   64.2 \n 5 female Other      413    8.23\n 6 male   Black      583   11.7 \n 7 male   Hispanic   290    5.82\n 8 male   Mexican    563   11.3 \n 9 male   White     3151   63.3 \n10 male   Other      393    7.89\n\n\n\nThis output gives us a clearer picture of the relationship between the two categorical variables by showing the percentage of each race within each gender group.\n\n\n\n\n11.3.2 Two Numeric Variables\n\nWhen both variables are numeric, we can correlation to explore the relationship between them.\n\n\n11.3.2.1 Correlation\n\nCorrelation measures the strength and direction of the linear relationship between two numeric variables. The most common measure is Pearson’s correlation coefficient.\nLet’s calculate the correlation between height and weight.\n\ndf %>%\n  drop_na(height, weight) |> \n  summarise(correlation = cor(height, weight))\n\n# A tibble: 1 × 1\n  correlation\n        <dbl>\n1       0.749\n\n\nAnother Way\n\n# Correlation between height and weight\ndf %>%\n  summarise(correlation = cor(height, weight, use = \"complete.obs\"))\n\n# A tibble: 1 × 1\n  correlation\n        <dbl>\n1       0.749\n\n\nHere, use = \"complete.obs\" ensures that rows with missing values (NA) are ignored during the correlation calculation, just like na.rm = TRUE would do.\n\n\n\n\n11.3.3 One categorical and One Numeric Variables\n\nWhen you have one categorical and one numeric variable, you’re often interested in comparing the distribution of the numeric variable across different categories. Group-wise summaries and box plots are common methods for this.\nLet’s look at the relationship between gender (categorical) and height (numeric).\nGroup-Wise Summaries We can calculate summary statistics (like mean and median) for height within each gender category.\n\n\n# Group-wise summary of height by gender\ndf %>%\n  group_by(gender) %>%\n  summarise(\n    mean_height = mean(height, na.rm = TRUE),\n    median_height = median(height, na.rm = TRUE),\n    sd_height = sd(height, na.rm = TRUE),\n    iqr_height = IQR(height, na.rm = TRUE)\n  )\n\n# A tibble: 2 × 5\n  gender mean_height median_height sd_height iqr_height\n  <fct>        <dbl>         <dbl>     <dbl>      <dbl>\n1 female        157.          161.      16.8       11.6\n2 male          167.          174.      21.9       13.2\n\n\n\n\n11.3.4 Publication Ready Tables for Two Variables\n\nWhen you need to present results in a polished, publication-ready format, the gtsummary package in R is an excellent tool. It allows you to easily create clean, professional tables summarizing relationships between two variables. Below is an example of how you can use gtsummary to generate a table for a two-variable analysis, showcasing how your results can be made ready for publication.\n\n# Create a publication-ready table for two categorical variables\ntable_cat <- df %>%\n  select(gender, race1) %>%\n  tbl_summary(by = gender, \n              label = race1 ~ \"Race/Ethnicity\") \n\n# Display the table\ntable_cat\n\n\n\n\n\n  \n    \n      Characteristic\n\n      female\nN = 5,020\n1\n      male\nN = 4,980\n1\n    \n  \n  \n    Race/Ethnicity\n\n\n        Black\n614 (12%)\n583 (12%)\n        Hispanic\n320 (6.4%)\n290 (5.8%)\n        Mexican\n452 (9.0%)\n563 (11%)\n        White\n3,221 (64%)\n3,151 (63%)\n        Other\n413 (8.2%)\n393 (7.9%)\n  \n  \n  \n    \n      1 n (%)\n\n    \n  \n\n\n\n\nIf you’re comparing a numeric variable across categories (e.g., height by gender), use the tbl_summary() function with the by argument.\n\n# Create a publication-ready table for a categorical and a numeric variables\n\ntable_cat_num <- df  |> \n  select(gender, height) |> \n  drop_na() |> \n  tbl_summary(by = gender, \n              label = height ~ \"Height\") \n\n# Display the table\ntable_cat_num\n\n\n\n\n\n  \n    \n      Characteristic\n\n      female\nN = 4,847\n1\n      male\nN = 4,800\n1\n    \n  \n  \n    Height\n161 (154, 166)\n174 (166, 179)\n  \n  \n  \n    \n      1 Median (Q1, Q3)\n\n    \n  \n\n\n\n\nIf you need mean and standard deviation instead of median and IQR, then\n\ntable_cat_num <- df  |> \n  select(gender, height) |> \n  drop_na() |> \n  tbl_summary(\n    by = gender,\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\")\n  ) \n\n# Display the table\ntable_cat_num\n\n\n\n\n\n  \n    \n      Characteristic\n\n      female\nN = 4,847\n1\n      male\nN = 4,800\n1\n    \n  \n  \n    height\n157 (17)\n167 (22)\n  \n  \n  \n    \n      1 Mean (SD)"
  },
  {
    "objectID": "inferential_statistics.html",
    "href": "inferential_statistics.html",
    "title": "4  Inferential Statistics",
    "section": "",
    "text": "4.1 Population, Sample and Sampling Process",
    "crumbs": [
      "Statistical Methods",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Inferential Statistics</span>"
    ]
  },
  {
    "objectID": "inferential_statistics.html#population-sample-and-sampling-process",
    "href": "inferential_statistics.html#population-sample-and-sampling-process",
    "title": "12  Inferential Statistics",
    "section": "12.1 Population, Sample and Sampling Process",
    "text": "12.1 Population, Sample and Sampling Process\n\nInferential statistics operates on the fundamental idea that we can infer characteristics of a population from a carefully selected sample. Since studying an entire population is often impractical or impossible due to time, cost, or accessibility constraints, researchers rely on samples. The goal is to use the sample data to draw conclusions or make estimates about the larger population.\n\nPopulation: This refers to the entire group of individuals or items that we are interested in studying. For example, in a medical study, the population could be all individuals with a certain medical condition.\nSample: A sample is a subset of the population that is selected for analysis. The sample must be representative of the population to ensure that the inferences made are valid. For example, selecting 500 individuals with the condition from different regions provides a sample from the larger population.\nSampling Process: The sampling process involves selecting individuals from the population in a way that ensures the sample reflects the population’s characteristics.\n\n\n\n\n\nImage modified from “Research Methods for the Social Sciences: An Introduction” (2020) by Valerie Sheppard."
  },
  {
    "objectID": "inferential_statistics.html#focus-areas",
    "href": "inferential_statistics.html#focus-areas",
    "title": "12  Inferential Statistics",
    "section": "12.2 Focus Areas",
    "text": "12.2 Focus Areas\n\nIn following chapters, we are focusing on three key areas of inferential statistics:\n\nHypothesis Testing\nInterval Estimation\nRegression Analysis\n\nEach of these areas plays a crucial role in understanding and applying inferential methods effectively. We will also explore how to implement these concepts using R, providing you with practical tools to analyze data and draw meaningful conclusions."
  },
  {
    "objectID": "regression.html",
    "href": "regression.html",
    "title": "6  Inferential Statistics: Regression Analysis",
    "section": "",
    "text": "6.1 Simple Linear Regression",
    "crumbs": [
      "Statistical Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Inferential Statistics: Regression Analysis</span>"
    ]
  },
  {
    "objectID": "regression.html#simple-linear-regression-slr",
    "href": "regression.html#simple-linear-regression-slr",
    "title": "9  Inferential Statistics: Regression Analysis",
    "section": "9.1 Simple Linear Regression (SLR)",
    "text": "9.1 Simple Linear Regression (SLR)\n\nSimple Linear regression (SLR) is one of the most widely used statistical methods for modeling the relationship between a dependent variable and one independent variable. However, to ensure the model’s accuracy and validity, several assumptions must be met.\n\n\n9.1.1 Assumptions of Simple Linear Regression\n\nThe acronym LINE helps us remember the key assumptions needed for making inferences and predictions with models based on linear least squares regression (LLSR).\nIn the case of simple linear regression with a single predictor \\(X\\), the assumptions are as follows:\n\nL (Linear relationship): The mean of the response variable \\(Y\\) is linearly related to the predictor variable \\(X\\).\nI (Independence of errors): The errors (or residuals) are independent, meaning that the distance between any two points from the regression line is unrelated.\nN (Normal distribution): For each value of \\(X\\), the response \\(Y\\) is normally distributed.\nE (Equal variance): The variance (or standard deviation) of the responses is constant for all values of \\(X\\).\n\nThese assumptions can be illustrated visually:\n\n\n\nAssumptions for linear least squares regression (LLSR) (Roback and Legler, 2021)\n\n\n\nL: The expected value of \\(Y\\) at each \\(X\\) lies along the regression line.\nI: We should verify that the design of the study ensures the errors are independent.\nN: The values of \\(Y\\) are normally distributed at each level of \\(X\\).\nE: The spread of \\(Y\\) is consistent across all levels of \\(X\\).\n\n\n\n\n9.1.2 The SLR Model\n\nIn SLR, the goal is to model the relationship between a dependent variable (response) and an independent variable (predictor). The model predicts the dependent variable based on the independent variable, helping us understand how changes in one variable impact the other.\nThe general form of a simple linear regression model is:\n\\[Y = \\beta_0 + \\beta_1 X + \\epsilon\\]\nWhere:\n\n\\(Y\\) is the dependent variable (the outcome we are predicting).\n\\(X\\) is the independent variable (the predictor).\n\\(\\beta_0\\) is the intercept (the expected value of \\(Y\\) when \\(X=0\\)).\n\\(\\beta_1\\) is the slope (the change in \\(Y\\) for each unit increase in \\(X\\)).\n\\(\\epsilon\\) is the error term, representing the variability in \\(Y\\) not explained by \\(X\\).\n\n\n\n\n9.1.3 Interpreting the Model\n\n\nIntercept (\\(\\beta_0\\)): The intercept tells us the expected value of the dependent variable when the independent variable is zero. However, in some cases, like the relationship between height and weight, interpreting the intercept might not make practical sense (e.g., predicting weight when height is zero).\nSlope (\\(\\beta_1\\)): The slope indicates the change in the dependent variable for a one-unit change in the independent variable. For example, if we are looking at the relationship between height and weight, the slope tells us how much weight is expected to increase (or decrease) for every unit increase in height.\nError term (\\(\\epsilon\\)): The error term captures the variation in the dependent variable that is not explained by the independent variable. In practice, our model won’t perfectly predict every observation, and this error term accounts for the difference between observed values and the values predicted by the model."
  },
  {
    "objectID": "regression.html#simple-linear-regression-slr-using-r",
    "href": "regression.html#simple-linear-regression-slr-using-r",
    "title": "9  Inferential Statistics: Regression Analysis",
    "section": "9.2 Simple Linear Regression (SLR) Using R",
    "text": "9.2 Simple Linear Regression (SLR) Using R\n\nIf the assumptions of simple linear regression are met, we can proceed with fitting the model to the data. In this section, we will explore how to perform simple linear regression using R. This method allows us to examine the relationship between a dependent variable (response) and an independent variable (predictor) and make predictions based on the data.\n\n\n9.2.1 Simple Linear Regression with a Numeric Independent Variable\n\nWhen dealing with a numeric independent variable, simple linear regression helps us understand how changes in the independent variable affect the dependent variable. In R, we can easily fit and evaluate this relationship using the lm() function.\nHere’s an example of performing simple linear regression when the independent variable is numeric:\nResearch Question\nUsing the NHANES dataset, our research question is:\nIn adults, is there a relationship between height (independent variable) and weight (dependent variable)?\n\nData Wrangling\n\nBefore we perform the Simple Linear Regression, we need to load and clean the NHANES dataset.\n\n\n# Instal and load packages\n\n#install.packages(pacman)\n\npacman::p_load(tidyverse, broom)\n\n\n# Load Data\n\ndf <- NHANES::NHANES\n\ndf <- df |> \n  filter(Age >= 18)\n\n# Set \"White\" as the reference category directly using factor()\ndf <- df |> \n  mutate(Race1 = factor(Race1, levels = c(\"White\", \"Black\", \"Mexican\", \"Hispanic\", \"Other\")))\n\n# Clean names\n\ndf <- df |> \n  janitor::clean_names()\n\nSLR Model\n\nNow, we build the linear regression model to examine the relationship between height and weight in adults.\n\n\nmodel <- lm(weight ~ height, data = df)\n\nsummary(model)\n\n\nCall:\nlm(formula = weight ~ height, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-41.329 -13.299  -2.887   9.673 149.022 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -78.06686    3.69698  -21.12   <2e-16 ***\nheight        0.94804    0.02186   43.38   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.01 on 7412 degrees of freedom\n  (67 observations deleted due to missingness)\nMultiple R-squared:  0.2025,    Adjusted R-squared:  0.2024 \nF-statistic:  1882 on 1 and 7412 DF,  p-value: < 2.2e-16\n\ntidy(model)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  -78.1      3.70       -21.1 3.66e-96\n2 height         0.948    0.0219      43.4 0       \n\n\n\n\nThe lm() function fits a simple linear regression model, and summary() provides detailed results including the regression coefficients, \\(R^2\\), and p-values.\nThe tidy() function from the broom package organizes the model output in a tidy format.\n\n\nSLR Model Interpretation\n\nThe Simple Linear Regression (SLR) model fits the relationship between height and weight in the adult population from the NHANES dataset. Below is a breakdown of the model output:\nModel Equation\nThe model equation based on the output can be written as:\n\\[\\hat{y} = -78.07 + 0.95 \\times \\text{Height}\\]\nWhere:\n\n\\(\\hat{y}\\) is the predicted weight (in kg)\nThe intercept (-78.07) represents the predicted weight when height is zero, which doesn’t have a practical interpretation in this context but is mathematically part of the model.\nThe slope (0.95) indicates that for each additional unit of height (in cm), the weight is expected to increase by approximately 0.95 kg, on average.\n\nCoefficients\n\nIntercept (-78.07): The negative intercept is not practically meaningful since height cannot be zero in adults, but it is part of the linear equation.\nHeight (0.95): The slope suggests that for every additional centimeter in height, weight increases by about 0.95 kg on average. The very small p-value (\\(<2e^-16\\)) indicates that the effect of height on weight is highly statistically significant.\n\nResiduals\nThe residuals show the differences between the observed and predicted values of weight:\n\nThe minimum residual is -41.33, and the maximum is 149.02, indicating some large deviations.\nThe median residual is -2.89, suggesting that most predictions are close to the observed values.\n\nGoodness of Fit\nR-squared (0.2025) Approximately 20.25% of the variance in weight is explained by height, which suggests that while height has a significant impact on weight, other factors also influence weight substantially.\nAdjusted R-squared (0.2024) Very close to the R-squared, confirming the model is reliable for this data.\nModel Significance\nThe F-statistic (1882) and its corresponding p-value (<2.2e−16) indicate that the model is highly significant, meaning height is a useful predictor for weight in this dataset.\nThe interpretation shows that height has a positive and significant relationship with weight, but the relatively low \\(R^2\\) value suggests that other factors besides height influence weight.\n\n\n\n9.2.2 Simple Linear Regression with a Categorical Independent Variable\nWhen dealing with a categorical independent variable, simple linear regression can be used to analyze how the different categories influence the dependent variable. In this case, we’ll explore the relationship between height and race in adults using the NHANES dataset.\nResearch Question\nIs there an association between race and weight in adult individuals from the NHANES dataset?\nSLR Model\nIn this analysis, we treat race as a categorical variable and examine its relationship with weight The regression equation for a categorical independent variable will include dummy coding (where one category is taken as the reference).\nHere’s how you can perform the simple linear regression with a categorical variable in R:\n\n# SLR Model with Categorical Independent Variable\nmodel_cat <- lm(weight ~ race1, data = df)\n\nsummary(model_cat)\n\n\nCall:\nlm(formula = weight ~ race1, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-48.787 -15.028  -2.828  11.872 142.813 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    82.5284     0.2992 275.794  < 2e-16 ***\nrace1Black      5.3582     0.7803   6.867 7.11e-12 ***\nrace1Mexican   -1.9117     0.8863  -2.157    0.031 *  \nrace1Hispanic  -4.2676     1.0616  -4.020 5.88e-05 ***\nrace1Other     -9.4982     0.9286 -10.229  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.02 on 7415 degrees of freedom\n  (61 observations deleted due to missingness)\nMultiple R-squared:  0.02501,   Adjusted R-squared:  0.02448 \nF-statistic: 47.55 on 4 and 7415 DF,  p-value: < 2.2e-16\n\n# Tidying the output for better interpretation\ntidy(model_cat)\n\n# A tibble: 5 × 5\n  term          estimate std.error statistic  p.value\n  <chr>            <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      82.5      0.299    276.   0       \n2 race1Black        5.36     0.780      6.87 7.11e-12\n3 race1Mexican     -1.91     0.886     -2.16 3.10e- 2\n4 race1Hispanic    -4.27     1.06      -4.02 5.88e- 5\n5 race1Other       -9.50     0.929    -10.2  2.14e-24\n\n\nSLR Model Interpretation\n:::{style=“text-align:justify”}\nThe Simple Linear Regression (SLR) model fits the relationship between race and weight in the adult population from the NHANES dataset. Below is a breakdown of the model output:\nModel Equation\nThe model equation based on the output can be written as:\n\\[\\hat{y} = 82.53 + 5.36 \\times \\text{(Black)} - 1.91 \\times \\text{(Mexican)} - 4.27 \\times \\text{(Hispanic)} - 9.50 \\times \\text{(Other)}\\]\nCoefficients\n\nIntercept: The estimated average weight for individuals in the reference category (White) is 82.53 units.\nrace1Black: Black individuals have an average weight that is 5.36 units heavier than the reference category (White).\nrace1Mexican: Mexican individuals weigh, on average, 1.91 units less than the reference category (White).\nrace1Hispanic: Hispanic individuals have an average weight that is 4.27 units less than the reference category (White).\nrace1Other: Individuals in the Other category weigh, on average, 9.50 units less than the reference category (White).\n\nResiduals\nResiduals indicate the differences between observed and predicted weights. They range from a minimum of -48.79 to a maximum of 142.81, showing variability in model predictions.\nGoodness of Fit\n\nResidual standard error: 21.02, indicating the average distance between observed and predicted values.\nMultiple R-squared: 0.02501, meaning that approximately 2.5% of the variability in weight is explained by race.\nAdjusted R-squared: 0.02448, which adjusts for the number of predictors in the model.\n\nModel Significance\nThe F-statistic is 47.55 with a p-value of < 2.2e-16, indicating that the model is statistically significant and at least one of the race categories significantly predicts weight."
  },
  {
    "objectID": "statistical_methods.html",
    "href": "statistical_methods.html",
    "title": "Statistical Methods",
    "section": "",
    "text": "Introduction to Biostatistics and Types of Variables",
    "crumbs": [
      "Statistical Methods"
    ]
  },
  {
    "objectID": "statistical_methods.html#introduction-to-biostatistics-and-types-of-variables",
    "href": "statistical_methods.html#introduction-to-biostatistics-and-types-of-variables",
    "title": "Statistical Methods",
    "section": "Introduction to Biostatistics and Types of Variables",
    "text": "Introduction to Biostatistics and Types of Variables\n\nBiostatistics\n\nBiostatistics is the application of statistical methods to biological and medical data. It helps clinicians make informed decisions based on data collected from clinical trials, observational studies, and patient records.\n\nVariables\nIf, as we observe a characteristic, we find that it takes on different values in different persons, places, or things, we label the characteristic a variable.\nFor example, if we are observing the characteristic’height’ in a group of people, we will notice that height varies from person to person. Therefore, height is a variable.\n\n\n\n\nTypes of Variables\n\nVariables are essential in data analysis and are categorized into four types:\n\n\n\nTypes of Variables\n\n\n\nNominal Variables: Categorical variables with no inherent order (e.g., blood type: A, B, AB, O).\nOrdinal Variables: Categorical variables with a meaningful order but unequal intervals (e.g., pain scale: mild, moderate, severe).\nDiscrete Variables: Numerical variables with distinct, countable values (e.g., number of patients in a clinic).\nContinuous Variables: Numerical variables that can take any value within a range (e.g., patient weight, height).\n\n\n\n\nTwo Major Parts of Statistics\n\nStatistics is divided into two main areas:\n\nDescriptive Statistics: Summarizing and describing data.\nInferential Statistics: Making predictions or inferences about a population based on a sample.\n\nExplore the following chapters to deepen your understanding of descriptive and inferential statistical methods, as well as how to implement these techniques using R."
  },
  {
    "objectID": "study_design.html#what-is-a-study-design",
    "href": "study_design.html#what-is-a-study-design",
    "title": "Epidemiological Study Designs",
    "section": "What is a ‘Study Design’ ?",
    "text": "What is a ‘Study Design’ ?\n\nA framework, or a set of methods and procedures used to collect and analyze data on variables specified in a particular research problem.\nA strategy, a direction to follow, in order that your objective is achieved or the question you ask is answered.\nA specific plan or protocol for conducting the study, which allows the investigator to translate the conceptual hypothesis into an operational one."
  },
  {
    "objectID": "study_design.html#what-determine-the-type-of-study-design",
    "href": "study_design.html#what-determine-the-type-of-study-design",
    "title": "Epidemiological Study Designs",
    "section": "What determine the type of Study Design?",
    "text": "What determine the type of Study Design?\n\nThe nature of question\nThe goal of research\nThe availability of resources"
  },
  {
    "objectID": "study_design.html#study-designs-are-broadly-categorised-into-two",
    "href": "study_design.html#study-designs-are-broadly-categorised-into-two",
    "title": "Epidemiological Study Designs",
    "section": "Study designs are broadly categorised into two",
    "text": "Study designs are broadly categorised into two\n\nObservational Study Design\nExperimental Study Design\n\nThe above links will take you to each of the study design and its characteristics, while to have a quick differentiation of the two, here is a table summarising the key points.\n\n\n\nTo Differentiate Observational & Experimental Study Design\n\n\n\n\n\n\n\nCharacteristics\nObservational.Study\nExperimental.Study\n\n\n\n\nDefinition\nObserves & measures variables without manipulating them\nManipulates the variables to determine their effect on another\n\n\nControl\nLimited control over extraneous variables or confounders\nStrict control over variables by process of randomisation\n\n\nGeneralisable\nMay not be generalised\nMay be generalised\n\n\nFeasibility\nLess expensive, less time consuming, easy to conduct\nExpensive, time consuming, complex conduct"
  },
  {
    "objectID": "observational_study_design.html",
    "href": "observational_study_design.html",
    "title": "5  Observational Study Design",
    "section": "",
    "text": "An observational study is a type of research design where researchers observe and analyze subjects without manipulating any variables. This approach allows for the examination of real-world conditions and associations between exposures (such as risk factors or interventions) and outcomes (like diseases or behaviors) in a natural setting.\n\n\n\n\n\n\n5.0.1 Types of Observational Study Design\nBroadly observational study designs are categorised as two:\n\nDescriptive Study Designs\nAnalytical Study Designs\n\n\n\n5.0.2 Differentiate Descriptive & Analytical study design\nThe above links will take you to each of the study design and its characteristics, while to have a quick differentiation of the two, here is a table summarising the key points.\n\n\n\nTo Differentiate Descriptive & Analytical Study Design\n\n\n\n\n\n\nDescriptive.Study\nAnalytical.Study\n\n\n\n\nDescribes phenomena as they exist\nUnderstands phenomena\n\n\nDescribes occurrence of outcome\nMeasures association between exposure & outcome\n\n\nDeals with ‘who’, ‘what’,‘when’, ‘where’\nDeals with ‘why’ and ‘how’\n\n\nGenerates hypothesis\nTests hypothesis\n\n\nNo comparison group\nPresence of comparison group\n\n\n\n\n\n\n\n5.0.3 Classification of Desciptive & Analytical study design\nEach of the above mentioned study designs are further sub-classified as shown in the figure below:\n\n\n\n\nflowchart LR\n  A[Observational Study] --> B(Descriptive Study)\n  A[Observational Study] --> C(Analytical Study)\n  B --> D(Case Reports)\n  B --> E(Case Series)\n  B --> F(Ecological Studies)\n  C --> G(Cross Sectional)\n  C --> H(Case Control)\n  C --> I[Cohort study]"
  },
  {
    "objectID": "experimental_study_design.html",
    "href": "experimental_study_design.html",
    "title": "8  Experimental Study Design",
    "section": "",
    "text": "An experimental study design is a research approach used to investigate causal relationships between variables. In this design, the researcher manipulates one or more independent variables to observe the effect on a dependent variable, while controlling for other factors.\n\n\n\n\n\n\n8.0.1 Types of Experimental Study Design\nBroadly experimental study designs are categorised as two:\n\nRandomised Control Trial\nNon Randomised Controlled Trial"
  },
  {
    "objectID": "understanding_research.html#origin-of-the-word-research",
    "href": "understanding_research.html#origin-of-the-word-research",
    "title": "1  Research: Etymology & Definition",
    "section": "1.1 Origin of the Word ‘Research’",
    "text": "1.1 Origin of the Word ‘Research’\nThe word research traces its origin to the Middle French term rechercher which translates to search again.\n\n\n\n\n\nThis verb is composed of the Old French prefix “re-” meaning “again” and “cerchier” which means “to search.” Therefore, “research” originally conveyed the idea of revisiting or closely examining something."
  },
  {
    "objectID": "understanding_research.html#defining-research",
    "href": "understanding_research.html#defining-research",
    "title": "1  Research: Etymology & Definition",
    "section": "1.2 Defining Research",
    "text": "1.2 Defining Research\nResearch may be defined as the creation of new knowledge and/or the use of existing knowledge in a new and creative way so as to generate new concepts, methodologies and understandings. This could include synthesis and analysis of previous research to the extent that it leads to new and creative outcomes.\n\n\n\n\n\nResearch is the cornerstone of human advancement, serving as a systematic inquiry that seeks to uncover new information, validate existing knowledge, and solve complex problems. Unlike other species, humans possess the unique ability to document and share their findings, creating a continuous thread of knowledge that connects past discoveries to present inquiries. This cumulative nature of knowledge is essential; each generation builds upon the insights of those who came before, allowing for profound advancements in science, technology, the arts, and social understanding.\nLet us visit few definitions given for research by luminaries in the field.\n\nResearch is an endeavor to discover, develop and verify knowledge. It is an intellectual process that has developed over hundreds of years, ever changing in purpose and form and always searching for truth.\n- C Francis Rummel\nResearch is a point of a view, an attitude of inquiry or a frame of mind.It asks questions which have till now not been asked, and it seeks to answer them by following a fairly definite procedure. It is not a mere theorizing, but rather an attempt to elicit facts and to face them once they have been assembled. Research is likewise not an attempt to bolster up pre-conceived opinions, and implies a readiness to accept the conclusions to which an inquiry leads, no matter how unwelcome they may prove. When successful, research adds to the scientific knowledge of the subject.\n- Robert Robertson Rusk\nBoth Rummel and Rusk emphasize the dynamic and inquisitive nature of research, though they approach it from slightly different angles. Rummel highlights the historical evolution of research as a continuous quest for truth, framing it as a rigorous intellectual process aimed at discovering and verifying knowledge. In contrast, Rusk focuses on the mindset and procedural rigor involved in research. He emphasizes the importance of questioning established norms and being open to unexpected findings. This definition stresses that research is not just about affirming existing beliefs but about genuinely seeking new knowledge through systematic inquiry.\nTo be sure the best research is that which is reliable, verifiable, and exhaustive, so that it provides information in which we have confidence. The main point here is that research is, literally speaking, a kind of human behaviour, an activity in which people engage.\n- Francis G Cornell\n\nCornell, here adds another dimension by asserting that effective research must be reliable, verifiable, and exhaustive. This perspective emphasizes the credibility of research findings and their importance in fostering confidence. By characterizing research as a form of human behavior, Fourier highlights its collaborative and social aspects, recognizing that research involves interaction and engagement among individuals."
  },
  {
    "objectID": "descriptive_observational_design.html#descriptive-study-design",
    "href": "descriptive_observational_design.html#descriptive-study-design",
    "title": "6  Observational Study Design: Descriptive",
    "section": "6.1 Descriptive Study Design",
    "text": "6.1 Descriptive Study Design\nDescriptive study design is a research methodology that aims to provide a detailed account of a population, phenomenon, or event. Unlike experimental designs, which seek to establish causal relationships through manipulation of variables, descriptive studies focus on painting a comprehensive picture of the characteristics and conditions as they exist in real life.\n\n6.1.1 The Primary Goal of Descriptive Studies\nTo describe the characteristics of a population or phenomenon. This includes gathering information about demographics, behaviors, attitudes, or conditions without influencing or altering them.\n\n\n6.1.2 Limitations of Descriptive Studies\nWhile descriptive studies provide essential insights, they do not establish causal relationships. They are limited by the absence of manipulation of variables, which means that findings must be interpreted with caution.\n\n\n6.1.3 Classification of Descriptive Study Design\n\n\n\n\nflowchart TB\n  A[Descriptive Study] --> B(Individual Level)\n  A[Descriptive Study] --> C(Population Level)\n  B --> D(Case Reports)\n  B --> E(Case Series)\n  C --> F(Ecological Studies)\n \n\n\n\n\n\n\n\n\nFirst let us delve into the individual level descriptive studies.\n\n\n6.1.4 Case Reports\nA case report is a detailed account of a specific clinical instance involving an individual patient. It serves as one of the earliest forms of medical research, emerging from the careful observations made by physicians and healthcare providers during their clinical practice. It serves as valuable tool for generating hypotheses, particularly in emerging health issues, as they document unique clinical presentations and associations.They provide detailed accounts of individual patient experiences, which can inform clinical practice and enhance understanding of rare or novel conditions.\n\n\n6.1.5 Role of Case Reports in Understanding the Zika Virus Outbreak\nThe emergence of the Zika virus in Latin America marked a significant public health concern, particularly due to its association with serious fetal anomalies, including microcephaly. Case reports played a crucial role in elucidating the relationship between Zika virus infection and adverse pregnancy outcomes, significantly enhancing our understanding of this public health crisis.\nA case report that first documented instance of maternal Zika virus infection associated with fetal microcephaly in Colombia, mirroring presentations previously observed in Brazil during the 2015–2016 outbreak is presented here\n\n\n6.1.6 Case Series"
  },
  {
    "objectID": "steps_in_research.html#steps-in-research-process",
    "href": "steps_in_research.html#steps-in-research-process",
    "title": "4  Research as a Process",
    "section": "4.1 Steps in Research Process",
    "text": "4.1 Steps in Research Process\nFamiliarity with the steps involved in the research process enhances the rigor of the research. Each stage, contributes to the validity of the findings and following established procedures reduces bias and increases the reliability of results.\nLet’s enlist the steps one by one.\n\nIdentifying the Research Problem\n\nThe research journey begins with the identification of a specific problem or question. This step requires a clear definition of the issue at hand, ensuring that the research is focused and relevant. Engaging with existing literature can help refine the problem and clarify its significance.\n\nReveiwing the Literature\n\nOnce the problem is identified, a comprehensive literature review is conducted. This step involves analyzing existing studies, theories, and frameworks related to the topic. The insights gained from this review not only provide context but also highlight gaps in current knowledge, informing the research design.\n\nFormulating a Research Question or Hypothesis\n\nBased on the literature review, researchers can formulate a hypothesis or a set of research questions. This step is crucial as it guides the direction of the study, framing what the researcher aims to discover or test. A well-defined hypothesis provides a clear focus for the research.\n\nResearch Design\n\nThe next step involves designing the research methodology. This includes selecting appropriate research methods (qualitative, quantitative, or mixed-methods), determining data collection techniques, and establishing a plan for analysis. A well-structured methodology is essential for obtaining valid and reliable results.\n\nData Collection\n\nWith the methodology in place, researchers proceed to collect data. This phase can involve surveys, experiments, interviews, or observational studies, depending on the research design. Effective data collection is critical, as it forms the foundation for analysis and interpretation.\n\nData Analysis & Hypothesis Testing\n\nAfter data collection, the analysis phase begins. Researchers employ statistical tools, qualitative analysis methods, or other techniques to interpret the data. This step reveals patterns, relationships, and insights, providing answers to the research questions or validating the hypothesis.\n\nInterpretation, Generalisation & Reporting\n\nThe final step is reporting the research findings. This includes writing a detailed report or paper, presenting at conferences, or publishing in academic journals. Sharing results is crucial for advancing knowledge and sparking further inquiry in the field."
  },
  {
    "objectID": "steps_in_research.html#research-as-a-cyclical-process",
    "href": "steps_in_research.html#research-as-a-cyclical-process",
    "title": "4  Research as a Process",
    "section": "4.2 Research as a Cyclical Process",
    "text": "4.2 Research as a Cyclical Process\nResearch is inherently iterative. The insights gained from interpretation can lead to new questions, hypotheses, or areas of interest. As researchers analyze their findings, they often uncover complexities that warrant further investigation, prompting a return to earlier stages of the research process.\n\n\n\n\nflowchart TB\n  A[Identifying the Research Problem] --> B(Reveiwing the Literature)\n  B--> C(Formulating a Research Question or Hypothesis)\n  C --> D(Research Design)\n  D --> E(Data Collection)\n  E --> F(Data Analysis & Hypothesis Testing)\n  F --> G(Interpretation, Generalisation & Reporting)\n  G --> A\n\n\n\n\n\n\n\n\nRecognizing research as a cyclical process emphasizes that each study is part of a larger continuum of knowledge. Each cycle contributes to a deeper understanding of complex issues, fostering innovation and discovery. This perspective encourages researchers to embrace uncertainty and view each finding not as a conclusion, but as a stepping stone to new questions and explorations."
  }
]